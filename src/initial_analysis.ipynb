{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pystan as stan\n",
    "import torch\n",
    "#import matplotlib as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221128T19Z</td>\n",
       "      <td>29029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221128T18Z</td>\n",
       "      <td>29878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221128T17Z</td>\n",
       "      <td>30452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221128T16Z</td>\n",
       "      <td>28969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221128T15Z</td>\n",
       "      <td>26456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  demand\n",
       "0  20221128T19Z   29029\n",
       "1  20221128T18Z   29878\n",
       "2  20221128T17Z   30452\n",
       "3  20221128T16Z   28969\n",
       "4  20221128T15Z   26456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CA hourly electricty consumption in MWh, 2015-2022\n",
    "ca_hourly_ec_data = pd.read_csv('data/ca_hourly_demand.csv')\n",
    "ca_hourly_ec_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "('time_idx', 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# add time index\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ca_hourly_ec_data)):\n\u001b[0;32m----> 3\u001b[0m     ca_hourly_ec_data\u001b[39m.\u001b[39;49mloc[:(\u001b[39m\"\u001b[39;49m\u001b[39mtime_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, i)]\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(ca_hourly_ec_data[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m][i]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m ca_hourly_ec_data\u001b[39m.\u001b[39msample(\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m521\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:814\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m--> 814\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_setitem_indexer(key)\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:703\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mrange\u001b[39m):\n\u001b[1;32m    700\u001b[0m     \u001b[39m# GH#45479 test_loc_setitem_range_key\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m--> 703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_to_indexer(key, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:1351\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1348\u001b[0m labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1350\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[39mreturn\u001b[39;00m labels\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mloc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1354\u001b[0m     \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m   1355\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)\n\u001b[1;32m   1356\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m   1357\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1358\u001b[0m ):\n\u001b[1;32m   1359\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mToo many indexers\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/numeric.py:234\u001b[0m, in \u001b[0;36mNumericIndex._convert_slice_indexer\u001b[0;34m(self, key, kind, is_frame)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# TODO: can we write this as a condition based on\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#  e.g. _should_fallback_to_positional?\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m# We always treat __getitem__ slicing as label-based\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[39m# translate to locations\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_indexer(key\u001b[39m.\u001b[39mstart, key\u001b[39m.\u001b[39mstop, key\u001b[39m.\u001b[39mstep)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49mkind, is_frame\u001b[39m=\u001b[39;49mis_frame)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:4327\u001b[0m, in \u001b[0;36mIndex._convert_slice_indexer\u001b[0;34m(self, key, kind, is_frame)\u001b[0m\n\u001b[1;32m   4325\u001b[0m     indexer \u001b[39m=\u001b[39m key\n\u001b[1;32m   4326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4327\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_indexer(start, stop, step)\n\u001b[1;32m   4329\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:6600\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   6557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6558\u001b[0m \u001b[39mCompute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[1;32m   6559\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6596\u001b[0m \u001b[39mslice(1, 3, None)\u001b[39;00m\n\u001b[1;32m   6597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deprecated_arg(kind, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mslice_indexer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 6600\u001b[0m start_slice, end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_locs(start, end, step\u001b[39m=\u001b[39;49mstep)\n\u001b[1;32m   6602\u001b[0m \u001b[39m# return a slice\u001b[39;00m\n\u001b[1;32m   6603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:6814\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   6812\u001b[0m end_slice \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   6813\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 6814\u001b[0m     end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_slice_bound(end, \u001b[39m\"\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   6815\u001b[0m \u001b[39mif\u001b[39;00m end_slice \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6816\u001b[0m     end_slice \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:6721\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   6719\u001b[0m \u001b[39m# we need to look up the label\u001b[39;00m\n\u001b[1;32m   6720\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 6721\u001b[0m     slc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   6722\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   6723\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/range.py:394\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    393\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m    395\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:5966\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5964\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5965\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5966\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: ('time_idx', 0)"
     ]
    }
   ],
   "source": [
    "# add time index\n",
    "for i in range(len(ca_hourly_ec_data)):\n",
    "    ca_hourly_ec_data.loc[:(\"time_idx\", i)]= int(ca_hourly_ec_data[\"date\"][i].replace(\"T\",\"\").replace(\"Z\",\"\"))\n",
    "ca_hourly_ec_data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        7042711\n",
      "1        7042710\n",
      "2        7042709\n",
      "3        7042708\n",
      "4        7042707\n",
      "          ...   \n",
      "64975          4\n",
      "64976          3\n",
      "64977          2\n",
      "64978          1\n",
      "64979          0\n",
      "Name: time_idx, Length: 64980, dtype: object\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Timeseries index should be of type integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [76], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m training_cutoff \u001b[39m=\u001b[39m ca_hourly_ec_data[\u001b[39m\"\u001b[39m\u001b[39mtime_idx\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m max_prediction_length\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(ca_hourly_ec_data[\u001b[39m\"\u001b[39m\u001b[39mtime_idx\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m training \u001b[39m=\u001b[39m TimeSeriesDataSet(\n\u001b[1;32m      8\u001b[0m     data\u001b[39m=\u001b[39;49mca_hourly_ec_data[\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mtime_idx \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m training_cutoff],\n\u001b[1;32m      9\u001b[0m     time_idx\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtime_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     target\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvolume\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     group_ids\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39magency\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msku\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     12\u001b[0m     min_encoder_length\u001b[39m=\u001b[39;49mmax_encoder_length \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m,  \u001b[39m# keep encoder length long (as it is in the validation set)\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m     max_encoder_length\u001b[39m=\u001b[39;49mmax_encoder_length,\n\u001b[1;32m     14\u001b[0m     min_prediction_length\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     max_prediction_length\u001b[39m=\u001b[39;49mmax_prediction_length,\n\u001b[1;32m     16\u001b[0m     static_categoricals\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39magency\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msku\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     17\u001b[0m     \u001b[39m#static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m#time_varying_known_categoricals=[\"special_days\", \"month\"],\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m#variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m#time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# time_varying_unknown_categoricals=[],\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# time_varying_unknown_reals=[\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39m#     \"volume\",\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m#     \"log_volume\",\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m#     \"industry_volume\",\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m#     \"soda_volume\",\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m#     \"avg_max_temp\",\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m#     \"avg_volume_by_agency\",\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m#     \"avg_volume_by_sku\",\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# ],\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m     target_normalizer\u001b[39m=\u001b[39;49mGroupNormalizer(\n\u001b[1;32m     32\u001b[0m         groups\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39magency\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msku\u001b[39;49m\u001b[39m\"\u001b[39;49m], transformation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msoftplus\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     33\u001b[0m     ),  \u001b[39m# use softplus and normalize by group\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m     add_relative_time_idx\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     35\u001b[0m     add_target_scales\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     36\u001b[0m     add_encoder_length\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[39m# create validation set (predict=True) which means to predict the last max_prediction_length points in time\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# for each series\u001b[39;00m\n\u001b[1;32m     41\u001b[0m validation \u001b[39m=\u001b[39m TimeSeriesDataSet\u001b[39m.\u001b[39mfrom_dataset(training, ca_hourly_ec_data, predict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, stop_randomization\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/data/timeseries.py:350\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_prediction_length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmin prediction length must be larger than 0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_prediction_length, \u001b[39mint\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mmin prediction length must be integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 350\u001b[0m \u001b[39massert\u001b[39;00m data[time_idx]\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTimeseries index should be of type integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m target\n\u001b[1;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m weight\n",
      "\u001b[0;31mAssertionError\u001b[0m: Timeseries index should be of type integer"
     ]
    }
   ],
   "source": [
    "max_prediction_length = 1\n",
    "max_encoder_length = 24\n",
    "training_cutoff = ca_hourly_ec_data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "print(ca_hourly_ec_data[\"time_idx\"])\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data=ca_hourly_ec_data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    #static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    #time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    #variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    #time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    # time_varying_unknown_categoricals=[],\n",
    "    # time_varying_unknown_reals=[\n",
    "    #     \"volume\",\n",
    "    #     \"log_volume\",\n",
    "    #     \"industry_volume\",\n",
    "    #     \"soda_volume\",\n",
    "    #     \"avg_max_temp\",\n",
    "    #     \"avg_volume_by_agency\",\n",
    "    #     \"avg_volume_by_sku\",\n",
    "    # ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, ca_hourly_ec_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m actuals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([y \u001b[39mfor\u001b[39;00m x, (y, weight) \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(val_dataloader)])\n\u001b[1;32m      3\u001b[0m baseline_predictions \u001b[39m=\u001b[39m Baseline()\u001b[39m.\u001b[39mpredict(val_dataloader)\n\u001b[1;32m      4\u001b[0m (actuals \u001b[39m-\u001b[39m baseline_predictions)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA daily weather conditions, 2020-17\n",
    "ca_hourly_ec_data = pd.read_csv('data/ca_hourly_demand.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
